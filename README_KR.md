# ğŸ“˜ Advancing Autoencoder Architectures for Enhanced Anomaly Detection in Multivariate Industrial Time Series

[![Language](https://img.shields.io/badge/language-English-orange.svg)](./README.md)
[![Language](https://img.shields.io/badge/language-Korean-blue.svg)](./README_KR.md)

ë³¸ ë¦¬í¬ì§€í† ë¦¬ëŠ” **Computers, Materials & Continua (CMC) 2024**ì— ê²Œì¬ëœ ë…¼ë¬¸ **"Advancing Autoencoder Architectures for Enhanced Anomaly Detection in Multivariate Industrial Time Series"**ì˜ ê³µì‹ êµ¬í˜„ì²´ ë° ì‹¤í—˜ ì½”ë“œë¥¼ í¬í•¨í•¨.

ë³¸ ì—°êµ¬ëŠ” **HAI (HIL-based Augmented ICS Security) 23.05** ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ì‚°ì—… ì œì–´ ì‹œìŠ¤í…œ(ICS)ì„ ìœ„í•œ í•˜ì´ë¸Œë¦¬ë“œ ì˜¤í† ì¸ì½”ë” ëª¨ë¸ì¸ **ConvBiLSTM-AE**ë¥¼ ì œì•ˆí•¨. ë˜í•œ, ë‹¤ì–‘í•œ ìµœì‹ (SOTA) ì´ìƒ íƒì§€ ëª¨ë¸ë“¤ê³¼ì˜ ë¹„êµ ì‹¤í—˜ í™˜ê²½ì„ ì œê³µí•¨.

---

## 1. ì£¼ìš” ê¸°ì—¬ (Key Contributions)

*   **ConvBiLSTM-AE ì œì•ˆ**: CNNì˜ ê³µê°„ì  íŠ¹ì§• ì¶”ì¶œ ëŠ¥ë ¥ê³¼ BiLSTMì˜ ì‹œê°„ì  ë¬¸ë§¥ í•™ìŠµ ëŠ¥ë ¥ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì˜¤í† ì¸ì½”ë” ëª¨ë¸.
*   **í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬**: HAI 23.05 ë°ì´í„°ì…‹ì— ëŒ€í•´ ë‹¤ì–‘í•œ Baseline (Linear, CAE, LSTM, BiLSTM) ë° SOTA ëª¨ë¸ë“¤ê³¼ì˜ ì„±ëŠ¥ ë¹„êµ.
*   **ê³ ë„í™”ëœ ë¶„ì„**:
    *   **VIF (ë¶„ì‚° íŒ½ì°½ ìš”ì¸)** ê¸°ë°˜ì˜ ë‹¤ì¤‘ê³µì„ ì„± ë³€ìˆ˜ ì œê±° ì „ì²˜ë¦¬ ìˆ˜í–‰.
    *   **Latent Space ì‹œê°í™”**: UMAP ë° PCAë¥¼ ì´ìš©í•œ ì„ë² ë”© ê³µê°„ ë¶„ì„.
    *   **Reconstruction Error ë¶„ì„**: ì´ë™ í‰ê· (Moving Average) í•„í„°ë¥¼ ì ìš©í•˜ì—¬ íƒì§€ ê°•ê±´ì„± í™•ë³´.

---

## 2. í”„ë¡œì íŠ¸ êµ¬ì¡° (Project Structure)

```text
HAI-Anomaly-Detection/
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.json                # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ë°ì´í„° ê²½ë¡œ ì„¤ì •
â”‚
â”œâ”€â”€ data/                          # ë°ì´í„°ì…‹ ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ hai-23.05/                 # HAI 23.05 ì›ë³¸ ë°ì´í„° (train1~4, test1~2)
â”‚   â””â”€â”€ outputs/                   # í•™ìŠµ ê²°ê³¼, ëª¨ë¸ ê°€ì¤‘ì¹˜, ë¡œê·¸ ì €ì¥
â”‚
â”œâ”€â”€ models/                        # [Proposed & Baselines] (TF/Keras)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ layers.py                  # Custom Attention Layer ë“±
â”‚   â””â”€â”€ architectures.py           # ConvBiLSTM-AE, BiGRU-AE ë“± ëª¨ë¸ ì •ì˜
â”‚
â”œâ”€â”€ comparisons/                   # [SOTA Benchmarks] (PyTorch)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ mtad_gat/              # Graph Attention Network
â”‚   â”‚   â”œâ”€â”€ omni_anomaly/          # Stochastic RNN (VAE)
â”‚   â”‚   â”œâ”€â”€ tran_ad/               # Transformer + Adversarial
â”‚   â”‚   â”œâ”€â”€ usad/                  # Unsupervised Adversarial AE
â”‚   â”‚   â”œâ”€â”€ daemon/                # Adversarial AE (Double Discriminator)
â”‚   â”‚   â””â”€â”€ madgan/                # LSTM-GAN
â”‚   â”‚
â”‚   â”œâ”€â”€ train_mtad_gat.py          # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ train_omni_anomaly.py
â”‚   â”œâ”€â”€ train_tran_ad.py
â”‚   â”œâ”€â”€ train_usad.py
â”‚   â”œâ”€â”€ train_daemon.py
â”‚   â””â”€â”€ train_madgan.py
â”‚
â”œâ”€â”€ utils/                         # ê³µí†µ ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py           # ë°ì´í„° ë¡œë“œ, ì •ê·œí™”, VIF, Windowing
â”‚   â”œâ”€â”€ metrics.py                 # F1-Score, Threshold ìµœì í™”, eTaPR
â”‚   â””â”€â”€ visualization.py           # Loss Plot, ROC/PR Curve, PCA/UMAP
â”‚
â”œâ”€â”€ train.py                       # [Main] ì œì•ˆ ëª¨ë¸(ConvBiLSTM-AE) í•™ìŠµ
â”œâ”€â”€ evaluate.py                    # [Main] ì œì•ˆ ëª¨ë¸ í‰ê°€
â”œâ”€â”€ analysis_eda.py                # [Analysis] EDA ë° ì„ë² ë”© ë¶„ì„
â”œâ”€â”€ requirements.txt               # ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ëª©ë¡
â””â”€â”€ README_KR.md                   # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ (êµ­ë¬¸)
```

---

## 3. ì‹¤í–‰ í™˜ê²½ ì„¤ì • (Setup)

### 3.1. ìš”êµ¬ ì‚¬í•­
*   Python 3.8+
*   **TensorFlow 2.x** (Main Model: ConvBiLSTM-AE)
*   **PyTorch 1.8+** (Comparison Models)
*   NVIDIA GPU (CUDA ì§€ì› ê¶Œì¥)

### 3.2. ì„¤ì¹˜
```bash
git clone <repository_url>
cd HAI-Anomaly-Detection
pip install -r requirements.txt
```

### 3.3. ë°ì´í„°ì…‹ ì¤€ë¹„
*   **HAI 23.05** ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ `data/hai-23.05/` ê²½ë¡œì— ìœ„ì¹˜ì‹œí‚´.
    *   Github: [https://github.com/icsdataset/hai](https://github.com/icsdataset/hai)

---

## 4. ì œì•ˆ ëª¨ë¸ ì‹¤í—˜ (Proposed Model)

ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” **ConvBiLSTM-AE** ë° Baseline ëª¨ë¸(Linear, CAE, LSTM, BiLSTM)ì„ í•™ìŠµí•˜ê³  í‰ê°€í•¨.

### 4.1. í•™ìŠµ (`train.py`)
```bash
# ConvBiLSTM-AE í•™ìŠµ (ê¸°ë³¸ ì„¤ì •)
python train.py --model Conv_BiLSTM_AE --epochs 60

# ë‹¤ë¥¸ Baseline ëª¨ë¸ í•™ìŠµ ì˜ˆì‹œ
python train.py --model BiLSTM_AE
```

### 4.2. í‰ê°€ (`evaluate.py`)
í•™ìŠµëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ Test 1, Test 2 ë°ì´í„°ì…‹ì— ëŒ€í•œ ì´ìƒ íƒì§€ ì„±ëŠ¥(F1, AUC, Precision, Recall)ì„ ì¸¡ì •í•¨.
```bash
python evaluate.py
```

### 4.3. ë¶„ì„ (`analysis_eda.py`)
ë°ì´í„°ì˜ ìƒê´€ê´€ê³„(Correlation Heatmap) ë¶„ì„ ë° í•™ìŠµëœ ì¸ì½”ë”ì˜ Latent Vectorì— ëŒ€í•œ **PCA ì‹œê°í™”**ë¥¼ ìˆ˜í–‰í•¨.
```bash
python analysis_eda.py
```

---

## 5. ë¹„êµ ëª¨ë¸ ì‹¤í—˜ (Benchmarks)

ìµœì‹  SOTA ëª¨ë¸ë“¤ê³¼ì˜ ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•´ PyTorch ê¸°ë°˜ì˜ êµ¬í˜„ì²´ë¥¼ ì œê³µí•¨. ëª¨ë“  ë¹„êµ ëª¨ë¸ì€ `utils/preprocessing.py`ë¥¼ í†µí•´ ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•¨.

| ëª¨ë¸ëª… | íŠ¹ì§• | ì‹¤í–‰ ëª…ë ¹ì–´ |
| :--- | :--- | :--- |
| **MTAD-GAT** | Graph Attention Network ê¸°ë°˜ ì‹œê³µê°„ ìƒê´€ê´€ê³„ ëª¨ë¸ë§ | `python comparisons/train_mtad_gat.py` |
| **OmniAnomaly** | Stochastic RNN (GRU-VAE) ê¸°ë°˜ í™•ë¥ ì  ëª¨ë¸ë§ | `python comparisons/train_omni_anomaly.py` |
| **TranAD** | Transformer + Adversarial Training ê¸°ë°˜ | `python comparisons/train_tran_ad.py` |
| **USAD** | AutoEncoder + GAN (Adversarial Training) | `python comparisons/train_usad.py` |
| **DAEMON** | Adversarial AE (Reconstruction & Latent Discriminator) | `python comparisons/train_daemon.py` |
| **MAD-GAN** | LSTM-GAN ê¸°ë°˜ (Latent Space Optimization í¬í•¨) | `python comparisons/train_madgan.py` |

> **ì°¸ê³ **: ëª¨ë“  ë¹„êµ ëª¨ë¸ ì‹¤í—˜ ê²°ê³¼ëŠ” `data/outputs/[ëª¨ë¸ëª…]/` í´ë”ì— ì €ì¥ë¨.

---

## 6. ì¸ìš© (Citation)

ë³¸ ì½”ë“œë¥¼ ì—°êµ¬ì— í™œìš©í•  ê²½ìš°, ì•„ë˜ ë…¼ë¬¸ì„ ì¸ìš© ë°”ëŒ.

```bibtex
@article{lee2024advancing,
  title={Advancing Autoencoder Architectures for Enhanced Anomaly Detection in Multivariate Industrial Time Series},
  author={Lee, Byeongcheon and Kim, Sangmin and Maqsood, Muazzam and Moon, Jihoon and Rho, Seungmin},
  journal={Computers, Materials & Continua},
  volume={81},
  number={1},
  pages={1275--1302},
  year={2024},
  publisher={Tech Science Press},
  doi={10.32604/cmc.2024.054826}
}
```

---

## 7. íŠ¹í—ˆ (Patent)

ë³¸ ì—°êµ¬ ê²°ê³¼ë¬¼ì€ ëŒ€í•œë¯¼êµ­ íŠ¹í—ˆì²­ì— ì¶œì›ë¨.

*   **ë°œëª…ì˜ ëª…ì¹­**: ë‹¤ë³€ìˆ˜ ì‚°ì—… ì‚¬ë¬¼ ë‹¨ë§ ê´€ë ¨ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ë”¥ ëŸ¬ë‹ ëª¨ë¸ì„ ê¸°ì´ˆë¡œ í•œ, ì´ìƒ íƒì§€ ë°©ë²• ê·¸ ì¥ì¹˜
    *   (METHOD FOR ANOMALY DETECTING BASED ON DEEP LEARNING MODEL IN TIME SERIES DATA RELATED TO MULTIVARIATE INDUSTRIAL THINGS TERMINALS, AND APPARATUS THEREOF)
*   **ì¶œì› ë²ˆí˜¸**: 10-2024-0161756
*   **ì¶œì› ì¼ì**: 2024.11.14
*   **ì¶œì›ì¸**: ì¤‘ì•™ëŒ€í•™êµ ì‚°í•™í˜‘ë ¥ë‹¨
*   **ë°œëª…ì**: ê¹€ìƒë¯¼, ì´ë³‘ì²œ, ë¬¸ì§€í›ˆ, ë…¸ìŠ¹ë¯¼, ë¬´ì•„ì  ë§ˆì¿ ìˆ˜ë“œ

---

## 8. ë¼ì´ì„ ìŠ¤ (License)

ì´ í”„ë¡œì íŠ¸ëŠ” **Creative Commons Attribution 4.0 International License (CC BY 4.0)**ì— ë”°ë¼ ë¼ì´ì„ ìŠ¤ê°€ ë¶€ì—¬ë¨.

This work is licensed under a Creative Commons Attribution 4.0 International License.

*   **ì €ì‘ê¶Œì**: Byeongcheon Lee, Sangmin Kim, Muazzam Maqsood, Jihoon Moon, Seungmin Rho
*   **ì¶œì²˜**: Computers, Materials & Continua (CMC), 2024, vol.81, no.1.

ë‹¨, `comparisons/` í´ë” ë‚´ì˜ ê° SOTA ë¹„êµ ëª¨ë¸ ì½”ë“œëŠ” í•´ë‹¹ ì›ë³¸ ë…¼ë¬¸ ë° ì €ìë“¤ì˜ ë¼ì´ì„ ìŠ¤ ì •ì±…ì„ ë”°ë¦„. ê° ëª¨ë¸ì˜ ì›ë³¸ ë¦¬í¬ì§€í† ë¦¬ë¥¼ ì°¸ì¡° ë°”ëŒ.